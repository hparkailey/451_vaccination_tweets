{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib, re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1337851215875608579</td>\n",
       "      <td>Gunther Fehlinger</td>\n",
       "      <td>Austria, Ukraine and Kosovo</td>\n",
       "      <td>End North Stream 2 now - the pipeline of corru...</td>\n",
       "      <td>2013-06-10 17:49:22</td>\n",
       "      <td>2731</td>\n",
       "      <td>5001</td>\n",
       "      <td>69344</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:06:00</td>\n",
       "      <td>it is a bit sad to claim the fame for success ...</td>\n",
       "      <td>['vaccination']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1337842295857623042</td>\n",
       "      <td>Ch.Amjad Ali</td>\n",
       "      <td>Islamabad</td>\n",
       "      <td>#ProudPakistani #LovePakArmy #PMIK @insafiansp...</td>\n",
       "      <td>2012-11-12 04:18:12</td>\n",
       "      <td>671</td>\n",
       "      <td>2368</td>\n",
       "      <td>20469</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 19:30:33</td>\n",
       "      <td>#CovidVaccine \\n\\nStates will start getting #C...</td>\n",
       "      <td>['CovidVaccine', 'COVID19Vaccine', 'US', 'paku...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1337841934170255365</td>\n",
       "      <td>Tamer Yazar</td>\n",
       "      <td>Turkey-Israel</td>\n",
       "      <td>Im Market Analyst, also Editor... working (fre...</td>\n",
       "      <td>2009-09-17 16:45:16</td>\n",
       "      <td>1302</td>\n",
       "      <td>78</td>\n",
       "      <td>339</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 19:29:07</td>\n",
       "      <td>while deaths are closing in on the 300,000 mar...</td>\n",
       "      <td>['PfizerBioNTech', 'Vaccine']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id          user_name                user_location  \\\n",
       "0   1340539111971516416         Rachel Roh    La Crescenta-Montrose, CA   \n",
       "2   1337858199140118533           eliüá±üáπüá™üá∫üëå                     Your Bed   \n",
       "6   1337851215875608579  Gunther Fehlinger  Austria, Ukraine and Kosovo   \n",
       "9   1337842295857623042       Ch.Amjad Ali                    Islamabad   \n",
       "10  1337841934170255365        Tamer Yazar                Turkey-Israel   \n",
       "\n",
       "                                     user_description         user_created  \\\n",
       "0   Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "2                                      heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "6   End North Stream 2 now - the pipeline of corru...  2013-06-10 17:49:22   \n",
       "9   #ProudPakistani #LovePakArmy #PMIK @insafiansp...  2012-11-12 04:18:12   \n",
       "10  Im Market Analyst, also Editor... working (fre...  2009-09-17 16:45:16   \n",
       "\n",
       "    user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0              405          1692             3247          False   \n",
       "2               10            88              155          False   \n",
       "6             2731          5001            69344          False   \n",
       "9              671          2368            20469          False   \n",
       "10            1302            78              339          False   \n",
       "\n",
       "                   date                                               text  \\\n",
       "0   2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "2   2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "6   2020-12-12 20:06:00  it is a bit sad to claim the fame for success ...   \n",
       "9   2020-12-12 19:30:33  #CovidVaccine \\n\\nStates will start getting #C...   \n",
       "10  2020-12-12 19:29:07  while deaths are closing in on the 300,000 mar...   \n",
       "\n",
       "                                             hashtags               source  \\\n",
       "0                                  ['PfizerBioNTech']  Twitter for Android   \n",
       "2   ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "6                                     ['vaccination']      Twitter Web App   \n",
       "9   ['CovidVaccine', 'COVID19Vaccine', 'US', 'paku...      Twitter Web App   \n",
       "10                      ['PfizerBioNTech', 'Vaccine']      Twitter Web App   \n",
       "\n",
       "    retweets  favorites  is_retweet  \n",
       "0          0          0       False  \n",
       "2          0          0       False  \n",
       "6          0          4       False  \n",
       "9          0          0       False  \n",
       "10         0          0       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"vaccination_all_tweets.csv\")\n",
    "tweets = tweets.dropna(axis=0) # TODO: discuss\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "user_name           0\n",
       "user_location       0\n",
       "user_description    0\n",
       "user_created        0\n",
       "user_followers      0\n",
       "user_friends        0\n",
       "user_favourites     0\n",
       "user_verified       0\n",
       "date                0\n",
       "text                0\n",
       "hashtags            0\n",
       "source              0\n",
       "retweets            0\n",
       "favorites           0\n",
       "is_retweet          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of missing values\n",
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(processed_features, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emoji\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# source : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://realpython.com/sentiment-analysis-python/\n",
    "def tokenize(text):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPDATED: #YellowFever &amp; #COVID19 #ImmunityPassports - Part Two\\n\\n#SARSCoV2 #PfizerBioNtech #Britain #December‚Ä¶ https://t.co/qKT7Rst9aW'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"vaccination_all_tweets.csv\")\n",
    "tweets = tweets.dropna(axis=0) # TODO: discuss\n",
    "original_text = tweets[\"text\"].copy(deep=True)\n",
    "original_text.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        same folks said daikon paste could treat cytok...\n",
       "2        coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "6        it is bit sad to claim the fame for success of...\n",
       "9        covidvaccinestates will start getting covid19v...\n",
       "10       while deaths are closing in on the 300000 mark...\n",
       "                               ...                        \n",
       "33708    zakharova russia has offered foreign embassy s...\n",
       "33712    breakingthe information attack targeting sputn...\n",
       "33713    pity as my personal preference would have been...\n",
       "33714    who in close contact with russia on sputnikv c...\n",
       "33716    breakingus targets europe in smear campaign ag...\n",
       "Name: text, Length: 19616, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text d\n",
    "def clean_text(text):\n",
    "#     text = str.lower(text) #lower case\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #rm websites\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text) # rm single characters \n",
    "    text = re.sub(r\"\\s\\s+\",\"\", text) # rm multiple spaces\n",
    "    text = re.sub(r\"#\",\"\", text) # rm hashtags\n",
    "    text = re.sub(r\"[(,?!)]\",\"\", text) # rm special characters \n",
    "    text = re.sub(\"@[^\\s]+\", \"\", text) # rm @twitter_id\n",
    "#     text = remove_emoji(text) # rm emoji\n",
    "    #text = re.sub(\"<[^>]*>\", \"\", text) # rm HTML markup\n",
    "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
    "    text = (re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")).strip()\n",
    "    # lower case since we assume letter case does not contain any significant information\n",
    "    #text = text.split()\n",
    "    #corpus = [txt for txt in text if not txt in set(stopwords.words('english'))]\n",
    "    #text = tokenize(text)\n",
    "                \n",
    "    #TODO : remove stop words or not? : expensive\n",
    "    return text\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: clean_text(x))\n",
    "tweets[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize\n",
    "### CountVectorizer constructs a bag-of-words model baesd on word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "docs = np.array(tweets[\"text\"])\n",
    "bag = count.fit_transform(docs) # constructed bow model and transformed sentences into sparse feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'same': 16293,\n",
       " 'folks': 7806,\n",
       " 'said': 16259,\n",
       " 'daikon': 5471,\n",
       " 'paste': 13853,\n",
       " 'could': 4740,\n",
       " 'treat': 19087,\n",
       " 'cytokine': 5453,\n",
       " 'storm': 17839,\n",
       " 'pfizerbiontech': 14064,\n",
       " 'coronavirus': 4653,\n",
       " 'sputnikv': 17549,\n",
       " 'astrazeneca': 2131,\n",
       " 'moderna': 12119,\n",
       " 'covid_19': 5062,\n",
       " 'russian': 16181,\n",
       " 'vaccine': 19789,\n",
       " 'is': 10086,\n",
       " 'created': 5288,\n",
       " 'to': 18850,\n",
       " 'last': 10821,\n",
       " 'years': 21046,\n",
       " 'it': 10123,\n",
       " 'bit': 2891,\n",
       " 'sad': 16223,\n",
       " 'claim': 4071,\n",
       " 'the': 18575,\n",
       " 'fame': 7422,\n",
       " 'for': 7835,\n",
       " 'success': 17968,\n",
       " 'of': 13249,\n",
       " 'vaccination': 19745,\n",
       " 'on': 13337,\n",
       " 'patriotic': 13884,\n",
       " 'competition': 4368,\n",
       " 'between': 2716,\n",
       " 'usa': 19606,\n",
       " 'canada': 3531,\n",
       " 'uk': 19340,\n",
       " 'and': 1683,\n",
       " 'covidvaccinestates': 5194,\n",
       " 'will': 20760,\n",
       " 'start': 17682,\n",
       " 'getting': 8263,\n",
       " 'covid19vaccine': 5020,\n",
       " 'monday': 12274,\n",
       " 'us': 19604,\n",
       " 'sayspakustv': 16412,\n",
       " 'nyc': 13164,\n",
       " 'healthcare': 8908,\n",
       " 'globalgoals': 8352,\n",
       " 'while': 20699,\n",
       " 'deaths': 5617,\n",
       " 'are': 1949,\n",
       " 'closing': 4152,\n",
       " 'in': 9606,\n",
       " '300000': 545,\n",
       " 'mark': 11605,\n",
       " 'millions': 11989,\n",
       " 'people': 13971,\n",
       " 'wait': 20405,\n",
       " 'first': 7690,\n",
       " 'trump': 19170,\n",
       " 'announces': 1750,\n",
       " 'rollout': 16054,\n",
       " 'less': 10971,\n",
       " 'than': 18520,\n",
       " '24': 436,\n",
       " 'hours': 9252,\n",
       " 'americans': 1624,\n",
       " 'be': 2546,\n",
       " 'vaccinated': 19700,\n",
       " 'against': 1359,\n",
       " 'updated': 19551,\n",
       " 'yellowfever': 21058,\n",
       " 'amp': 1646,\n",
       " 'covid19': 4939,\n",
       " 'immunitypassports': 9522,\n",
       " 'part': 13809,\n",
       " 'twosarscov2': 19295,\n",
       " 'britain': 3268,\n",
       " 'december': 5638,\n",
       " 'iran': 10063,\n",
       " 'reports': 15739,\n",
       " '8201': 932,\n",
       " 'new': 12789,\n",
       " 'cases': 3653,\n",
       " '221': 412,\n",
       " 'rake': 15283,\n",
       " 'billions': 2823,\n",
       " 'from': 8009,\n",
       " 'its': 10155,\n",
       " 'expensive': 7247,\n",
       " 'covidvaccine': 5147,\n",
       " 'but': 3424,\n",
       " 'refuses': 15561,\n",
       " 'cut': 5427,\n",
       " 'price': 14764,\n",
       " 'lowe': 11310,\n",
       " 'administration': 1245,\n",
       " 'failed': 7384,\n",
       " 'deliver': 5741,\n",
       " 'promises': 14920,\n",
       " 'shocker': 16843,\n",
       " 'covidiots': 5099,\n",
       " 'anyone': 1822,\n",
       " 'wondering': 20854,\n",
       " 'why': 20730,\n",
       " 'day': 5562,\n",
       " 'after': 1344,\n",
       " 'approval': 1912,\n",
       " 'were': 20639,\n",
       " 'all': 1500,\n",
       " 'we': 20526,\n",
       " 'tol': 18906,\n",
       " 'no': 12953,\n",
       " 'done': 6263,\n",
       " 'thankyounhs': 18555,\n",
       " 'making': 11469,\n",
       " 'dream': 6407,\n",
       " 'poss': 14570,\n",
       " 'wear': 20537,\n",
       " 'mask': 11643,\n",
       " 'wash': 20489,\n",
       " 'your': 21121,\n",
       " 'hands': 8742,\n",
       " 'remain': 15665,\n",
       " 'socially': 17287,\n",
       " 'distant': 6122,\n",
       " 'when': 20682,\n",
       " 'possible': 14574,\n",
       " 'stayhome': 17723,\n",
       " 'stayathome': 17718,\n",
       " 'stayathomesavelives': 17719,\n",
       " 'fda': 7508,\n",
       " 'apprentice': 1900,\n",
       " 'style': 17932,\n",
       " 'approve': 1918,\n",
       " 'or': 13457,\n",
       " 'you': 21105,\n",
       " 'interesting': 9979,\n",
       " 'very': 20218,\n",
       " 'detailed': 5877,\n",
       " 'article': 2023,\n",
       " 'showing': 16927,\n",
       " 'up': 19544,\n",
       " 'how': 9266,\n",
       " 'well': 20627,\n",
       " 'tested': 18487,\n",
       " 'supplychain': 18082,\n",
       " 'with': 20802,\n",
       " 'sharedvisibility': 16764,\n",
       " 'help': 8983,\n",
       " 'trumpvaccine': 19180,\n",
       " 'pfizervaccine': 14158,\n",
       " 'pfizercovidvaccinepfizer': 14140,\n",
       " 'covid': 4938,\n",
       " '19': 269,\n",
       " 'belong': 2652,\n",
       " 'so': 17271,\n",
       " 'far': 7440,\n",
       " 'only': 13374,\n",
       " 'death': 5614,\n",
       " 'nothing': 13037,\n",
       " 'worry': 20932,\n",
       " 'about': 1055,\n",
       " 'then': 18611,\n",
       " 'covidvaccines': 5184,\n",
       " 'icymi': 9407,\n",
       " 'authorized': 2273,\n",
       " 'united': 19466,\n",
       " 'states': 17702,\n",
       " 'night': 12906,\n",
       " 'an': 1657,\n",
       " 'immigrant': 9502,\n",
       " 'muslim': 12479,\n",
       " 'couple': 4777,\n",
       " 'find': 7652,\n",
       " 'pfizerproud': 14154,\n",
       " 'ladies': 10753,\n",
       " 'gentlemen': 8222,\n",
       " 'now': 13079,\n",
       " 'have': 8843,\n",
       " 'experts': 7268,\n",
       " 'each': 6543,\n",
       " 'every': 7122,\n",
       " 'household': 9258,\n",
       " 'pakistan': 13717,\n",
       " 'oxfordvaccine': 13668,\n",
       " 'fact': 7362,\n",
       " 'sheet': 16786,\n",
       " 'providers': 15007,\n",
       " 'administering': 1237,\n",
       " 'vaccinepfizerbiontechcovidvaccine': 19918,\n",
       " 'one': 13342,\n",
       " 'which': 20697,\n",
       " 'doesn': 6203,\n",
       " 'any': 1814,\n",
       " 'side': 16963,\n",
       " 'effectsthe': 6650,\n",
       " 'recipients': 15476,\n",
       " 'caregiverspfizerbiontechcovidvaccine': 3619,\n",
       " 'authorizes': 2274,\n",
       " 'emergency': 6781,\n",
       " 'use': 19616,\n",
       " 'covidvaccinepoisons': 5181,\n",
       " 'enough': 6881,\n",
       " 'left': 10928,\n",
       " 'effects': 6644,\n",
       " 'like': 11079,\n",
       " 'bellspalsy': 2650,\n",
       " 'as': 2035,\n",
       " 'they': 18658,\n",
       " 'flocking': 7766,\n",
       " 'gets': 8254,\n",
       " 'set': 16704,\n",
       " 'roll': 16047,\n",
       " 'out': 13542,\n",
       " 'preparations': 14699,\n",
       " 'pick': 14283,\n",
       " 'pace': 13685,\n",
       " 'across': 1156,\n",
       " 'eu': 7037,\n",
       " 'meanwhile': 11757,\n",
       " 've': 20178,\n",
       " 'never': 12783,\n",
       " 'been': 2586,\n",
       " 'excited': 7177,\n",
       " 'get': 8250,\n",
       " 'vaccinessavelives': 19994,\n",
       " 'vaccineswork': 20012,\n",
       " 'doses': 6321,\n",
       " 'arrived': 2009,\n",
       " 'oregon': 13476,\n",
       " 'watch': 20500,\n",
       " 'morningsonthedove': 12340,\n",
       " '6am': 855,\n",
       " '9am': 1001,\n",
       " 'tomorrow': 18919,\n",
       " 'det': 5874,\n",
       " 'has': 8818,\n",
       " 'told': 18907,\n",
       " 'world': 20913,\n",
       " 'health': 8904,\n",
       " 'organization': 13488,\n",
       " 'does': 6202,\n",
       " 'not': 13027,\n",
       " 'intend': 9958,\n",
       " 'import': 9574,\n",
       " 'bec': 2567,\n",
       " 'concerned': 4412,\n",
       " 'vaccinecheck': 19815,\n",
       " 'my': 12507,\n",
       " 'recap': 15443,\n",
       " 'members': 11844,\n",
       " 'delivered': 5743,\n",
       " 'this': 18673,\n",
       " 'morning': 12336,\n",
       " 'teamsters': 18378,\n",
       " 'ups': 19573,\n",
       " 'covid19pfizer': 4993,\n",
       " 'dose': 6308,\n",
       " 'next': 12860,\n",
       " 'weekend': 20588,\n",
       " 'seeing': 16588,\n",
       " 'unboxing': 19387,\n",
       " 'just': 10432,\n",
       " 'made': 11397,\n",
       " 'female': 7569,\n",
       " 'sterilization': 17761,\n",
       " 'pfizer': 14058,\n",
       " 'untested': 19527,\n",
       " 'liabilitiescrimesagainsthumanity': 11018,\n",
       " 'key': 10561,\n",
       " 'crushcovid': 5365,\n",
       " 'milestone': 11972,\n",
       " 'achieved': 1139,\n",
       " 'shutting': 16946,\n",
       " 'down': 6366,\n",
       " 'coverup': 4936,\n",
       " 'pfizerbiontechuntested': 14126,\n",
       " 'inbox': 9621,\n",
       " 'says': 16405,\n",
       " 'shipments': 16818,\n",
       " 'continue': 4556,\n",
       " 'ship': 16813,\n",
       " 'missouri': 12070,\n",
       " '21': 389,\n",
       " 'vaccinat': 19693,\n",
       " 'germany': 8245,\n",
       " 'based': 2490,\n",
       " 'lets': 10981,\n",
       " 'hope': 9199,\n",
       " 'small': 17218,\n",
       " 'numbers': 13133,\n",
       " 'screenshot': 16524,\n",
       " 'that': 18564,\n",
       " 'qp': 15158,\n",
       " 'exchange': 7172,\n",
       " 'unfortunately': 19450,\n",
       " 'hansard': 8751,\n",
       " 'physician': 14276,\n",
       " 'currently': 5419,\n",
       " 'cried': 5307,\n",
       " 'ontarian': 13386,\n",
       " 'was': 20488,\n",
       " 'minutes': 12035,\n",
       " 'later': 10837,\n",
       " 'psw': 15031,\n",
       " 'anita': 1731,\n",
       " 'quidangen': 15213,\n",
       " 'toronto': 18960,\n",
       " 'wouldyou': 20948,\n",
       " 'take': 18271,\n",
       " 'listen': 11132,\n",
       " 'expert': 7265,\n",
       " 'ugursahin': 19335,\n",
       " 'ozlemtureci': 13678,\n",
       " 'scientists': 16498,\n",
       " 'husband': 9342,\n",
       " 'wife': 20749,\n",
       " 'saving': 16390,\n",
       " 'their': 18596,\n",
       " 'works': 20906,\n",
       " 'explanation': 7285,\n",
       " 'vaccinations': 19774,\n",
       " 'today': 18861,\n",
       " 'thank': 18522,\n",
       " 'everyone': 7128,\n",
       " 'stepping': 17757,\n",
       " 'anitaquidangen': 1732,\n",
       " 'personal': 14014,\n",
       " 'support': 18088,\n",
       " 'worker': 20889,\n",
       " 'became': 2569,\n",
       " 'receive': 15450,\n",
       " 'state': 17695,\n",
       " 'supposed': 18093,\n",
       " '35100': 600,\n",
       " 'total': 18976,\n",
       " 'week': 20584,\n",
       " 'remained': 15666,\n",
       " '30225': 550,\n",
       " 'orangecounty': 13460,\n",
       " '25k': 467,\n",
       " 'ofpfizerbiontech': 13284,\n",
       " 'by': 3441,\n",
       " 'wednesday': 20573,\n",
       " 'dec': 5629,\n",
       " '15': 187,\n",
       " 'confirms': 4463,\n",
       " 'breaking': 3188,\n",
       " 'legacy': 10935,\n",
       " 'registered': 15587,\n",
       " 'ruh': 16136,\n",
       " 'roh': 16040,\n",
       " 'also': 1567,\n",
       " 'saw': 16394,\n",
       " 'heard': 8938,\n",
       " 'michelle': 11933,\n",
       " 'rempel': 15694,\n",
       " 'suggest': 18001,\n",
       " 'during': 6510,\n",
       " 'house': 9255,\n",
       " 'canadian': 3538,\n",
       " 'pm': 14417,\n",
       " 'justin': 10450,\n",
       " 'trudeau': 19158,\n",
       " 'announced': 1747,\n",
       " 'arrival': 2006,\n",
       " 'vials': 20238,\n",
       " 'country': 4768,\n",
       " 'biontech': 2846,\n",
       " 'privileged': 14821,\n",
       " 'offered': 13264,\n",
       " 'would': 20946,\n",
       " 'encourage': 6824,\n",
       " 'll': 11177,\n",
       " 'protect': 14965,\n",
       " 'peo': 13968,\n",
       " 'vaccines': 19937,\n",
       " 'receivers': 15455,\n",
       " 'momentous': 12259,\n",
       " 'science': 16473,\n",
       " 'half': 8709,\n",
       " 'way': 20516,\n",
       " 'there': 18639,\n",
       " 'can': 3529,\n",
       " 'kids': 10600,\n",
       " 'towards': 18995,\n",
       " 'herd': 9010,\n",
       " 'immunity': 9520,\n",
       " 'ontario': 13388,\n",
       " '1st': 318,\n",
       " 'todayontario': 18875,\n",
       " 'some': 17321,\n",
       " 'good': 8423,\n",
       " 'news': 12813,\n",
       " 'california': 3477,\n",
       " 'gov': 8468,\n",
       " 'gav': 8166,\n",
       " 'where': 20686,\n",
       " 'pandemic': 13753,\n",
       " 'pcrgate': 13918,\n",
       " 'condemic': 4427,\n",
       " 'billgatesisnotadoctor': 2819,\n",
       " 'pfizerbiontechjust': 14095,\n",
       " 'employee': 6804,\n",
       " 'boardroom': 3005,\n",
       " 'yet': 21079,\n",
       " 'covid19vaccines': 5043,\n",
       " 'speak': 17434,\n",
       " 'being': 2624,\n",
       " 'admin': 1227,\n",
       " 'happy': 8769,\n",
       " 'cold': 4230,\n",
       " 'chain': 3801,\n",
       " 'daythe': 5583,\n",
       " 'distributed': 6132,\n",
       " 'county': 4775,\n",
       " 'coldchain': 4232,\n",
       " 'industrial': 9746,\n",
       " 'cre': 5281,\n",
       " 'received': 15451,\n",
       " 'feel': 7545,\n",
       " 'lucky': 11334,\n",
       " 'several': 16719,\n",
       " 'countries': 4759,\n",
       " 'including': 9642,\n",
       " 'approving': 1923,\n",
       " 'update': 19548,\n",
       " 'nurse': 13143,\n",
       " 'york': 21102,\n",
       " 'city': 4056,\n",
       " 'person': 14013,\n",
       " 'shipment': 16817,\n",
       " 'front': 8013,\n",
       " 'line': 11105,\n",
       " 'kind': 10612,\n",
       " 'surreal': 18124,\n",
       " 'dropping': 6445,\n",
       " 'president': 14723,\n",
       " 'administered': 1234,\n",
       " 'arrive': 2008,\n",
       " 'fedex': 7538,\n",
       " 'transport': 19066,\n",
       " 'initial': 9822,\n",
       " 'fdx': 7511,\n",
       " 'campaign': 3517,\n",
       " 'begins': 2603,\n",
       " 'quebec': 15188,\n",
       " 'residents': 15805,\n",
       " 'at': 2174,\n",
       " 'maimonides': 11436,\n",
       " 'among': 1641,\n",
       " 'seniors': 16643,\n",
       " 'kudos': 10704,\n",
       " '13th': 159,\n",
       " 'involvement': 10046,\n",
       " 'full': 8061,\n",
       " 'distribution': 6135,\n",
       " 'efforts': 6684,\n",
       " 'end': 6829,\n",
       " 'sight': 16979,\n",
       " 'many': 11569,\n",
       " 'coworkers': 5253,\n",
       " 'our': 13534,\n",
       " 'selected': 16607,\n",
       " 'ports': 14556,\n",
       " 'entry': 6915,\n",
       " 'sunday': 18031,\n",
       " 'singapore': 17034,\n",
       " 'approves': 1921,\n",
       " 'expected': 7238,\n",
       " 'lee': 10924,\n",
       " 'hsien': 9284,\n",
       " 'loong': 11263,\n",
       " 'here': 9012,\n",
       " 'lipids': 11125,\n",
       " 'used': 19620,\n",
       " 'lipid': 11123,\n",
       " 'nanoparticle': 12587,\n",
       " 'mrnabiontech': 12410,\n",
       " 'pfizerbiontechcovidvaccine': 14081,\n",
       " 'begin': 2599,\n",
       " 'more': 12332,\n",
       " 'approvals': 1916,\n",
       " 'expects': 7243,\n",
       " 'shots': 16893,\n",
       " 'decemb': 5637,\n",
       " 'distributions': 6136,\n",
       " 'sites': 17116,\n",
       " 'nationwide': 12650,\n",
       " 'asian': 2057,\n",
       " 'coronavirusvaccine': 4683,\n",
       " 'ex': 7146,\n",
       " 'electoralcollege': 6725,\n",
       " 'formally': 7873,\n",
       " 'casts': 3664,\n",
       " 'votes': 20371,\n",
       " 'detroitlions': 5893,\n",
       " 'los': 11271,\n",
       " 'virusvaccinepandemic': 20300,\n",
       " 'tomorrowso': 18920,\n",
       " 'honoured': 9187,\n",
       " 'exciting': 7184,\n",
       " 'team': 18361,\n",
       " 'primary': 14775,\n",
       " 'care': 3613,\n",
       " 'who': 20712,\n",
       " 'should': 16907,\n",
       " 'yetvia': 21082,\n",
       " 'maskuppfizer': 11655,\n",
       " 'outpandemic': 13558,\n",
       " 'vaccinefirst': 19855,\n",
       " 'decembercoronavirus': 5639,\n",
       " 'immunized': 9526,\n",
       " '100': 23,\n",
       " 'million': 11985,\n",
       " 'march': 11583,\n",
       " 'slaoui': 17166,\n",
       " 'plan': 14356,\n",
       " 'tackle': 18252,\n",
       " 'really': 15417,\n",
       " 'effective': 6634,\n",
       " 'early': 6552,\n",
       " 'pandemicmore': 13757,\n",
       " 'bn': 2994,\n",
       " 'aside': 2060,\n",
       " 'fo': 7794,\n",
       " 'phase': 14209,\n",
       " '28': 485,\n",
       " 'free': 7954,\n",
       " 'began': 2596,\n",
       " 'following': 7817,\n",
       " 'final': 7638,\n",
       " 'cdc': 3716,\n",
       " 'true': 19164,\n",
       " 'question': 15196,\n",
       " 'needs': 12712,\n",
       " 'given': 8316,\n",
       " 'few': 7589,\n",
       " 'minute': 12034,\n",
       " 'emergencyauthorization': 6782,\n",
       " 'unlikely': 19490,\n",
       " 'available': 2285,\n",
       " 'india': 9668,\n",
       " 'mass': 11658,\n",
       " 'read': 15387,\n",
       " 'drive': 6429,\n",
       " 'due': 6483,\n",
       " 'tuesday': 19218,\n",
       " 'super': 18048,\n",
       " 'thrilled': 18721,\n",
       " 'according': 1111,\n",
       " 'latest': 10839,\n",
       " 'figures': 7623,\n",
       " 'maximum': 11714,\n",
       " 'over': 13576,\n",
       " '16': 219,\n",
       " 'mil': 11963,\n",
       " 'vaccinepennsylvania': 19915,\n",
       " 'nursing': 13152,\n",
       " 'homes': 9164,\n",
       " 'pennsylvania': 13961,\n",
       " 'prepare': 14700,\n",
       " 'distribut': 6130,\n",
       " 'politicians': 14482,\n",
       " 'essentialworkers': 7002,\n",
       " 'sciencematters': 16481,\n",
       " 'newspfizerbiontech': 12837,\n",
       " 'other': 13518,\n",
       " 'coming': 4283,\n",
       " 'money': 12285,\n",
       " 'mr': 12402,\n",
       " 'twain': 19272,\n",
       " 'apt29': 1935,\n",
       " 'aka': 1446,\n",
       " 'cozybear': 5256,\n",
       " 'hacker': 8682,\n",
       " 'group': 8593,\n",
       " 'suspected': 18137,\n",
       " 'hacking': 8684,\n",
       " 'ip': 10056,\n",
       " 'federal': 7534,\n",
       " 'agencies': 1368,\n",
       " 'treas': 19084,\n",
       " 'urgently': 19594,\n",
       " 'needed': 12705,\n",
       " 'africa': 1335,\n",
       " 'ghana': 8281,\n",
       " 'nigeria': 12903,\n",
       " 'egypt': 6690,\n",
       " 'southafrica': 17384,\n",
       " 'rest': 15835,\n",
       " 'comes': 4278,\n",
       " 'might': 11956,\n",
       " 'call': 3484,\n",
       " 'ahead': 1399,\n",
       " 'liarinchief': 11023,\n",
       " 'had': 8688,\n",
       " 'do': 6174,\n",
       " 'pfizercovidvaccine': 14137,\n",
       " 'hacked': 8681,\n",
       " 'days': 5572,\n",
       " 'agoustreasury': 1385,\n",
       " 'hack': 8680,\n",
       " 'whol': 20719,\n",
       " 'safe': 16234,\n",
       " 're': 15367,\n",
       " 'nowhere': 13084,\n",
       " 'near': 12690,\n",
       " '2030': 377,\n",
       " 'premature': 14690,\n",
       " 'innoculation': 9852,\n",
       " 'pfizerbiontechcdnpoli': 14075,\n",
       " 'harharmahadev': 8799,\n",
       " 'batch': 2510,\n",
       " 'yay': 21027,\n",
       " 'congratulations': 4479,\n",
       " 'welcoming': 20625,\n",
       " 'tonightthe': 18927,\n",
       " '30k': 557,\n",
       " 'arriving': 2012,\n",
       " 'cou': 4734,\n",
       " 'information': 9798,\n",
       " 'severe': 16720,\n",
       " 'allergies': 1514,\n",
       " 'welp': 20633,\n",
       " 'thanks': 18533,\n",
       " 'already': 1561,\n",
       " 'aren': 1952,\n",
       " 'going': 8409,\n",
       " 'quite': 15218,\n",
       " 'planned': 14362,\n",
       " 'these': 18646,\n",
       " 'heavens': 8954,\n",
       " 'too': 18933,\n",
       " 'stupid': 17929,\n",
       " 'reason': 15427,\n",
       " 'even': 7108,\n",
       " 'slow': 17203,\n",
       " 'dummy': 6494,\n",
       " 'pademics': 13694,\n",
       " 'slither': 17192,\n",
       " 'away': 2317,\n",
       " 'alr': 1558,\n",
       " 'covidvaccinepfizerbiontech': 5178,\n",
       " 'what': 20664,\n",
       " 'process': 14843,\n",
       " 'definitely': 5702,\n",
       " 'thought': 18700,\n",
       " 'everything': 7134,\n",
       " 'publicity': 15053,\n",
       " 'wise': 20792,\n",
       " 'turkey': 19245,\n",
       " 'toll': 18913,\n",
       " 'reaches': 15372,\n",
       " '16417': 226,\n",
       " 'coronaviruspandemic': 4673,\n",
       " 'infections': 9773,\n",
       " 'worldwide': 20928,\n",
       " 'unitedstates': 19472,\n",
       " '220575': 411,\n",
       " 'brazil': 3173,\n",
       " '43279': 681,\n",
       " '30805': 552,\n",
       " 'corona': 4629,\n",
       " 'america': 1619,\n",
       " 'he': 8875,\n",
       " 'leave': 10914,\n",
       " 'behind': 2614,\n",
       " 'donaldtrump': 6255,\n",
       " 'joebiden': 10333,\n",
       " 'newyork': 12855,\n",
       " 'washington': 20490,\n",
       " 'whitehouse': 20709,\n",
       " 'claiming': 4073,\n",
       " 'his': 9099,\n",
       " 'administrati': 1242,\n",
       " 'go': 8382,\n",
       " 'grateful': 8533,\n",
       " 'workers': 20890,\n",
       " 'tampa': 18311,\n",
       " 'fl': 7729,\n",
       " 'acip': 1144,\n",
       " 'released': 15643,\n",
       " 'interim': 9984,\n",
       " 'guidance': 8632,\n",
       " 'recommended': 15493,\n",
       " 'persons': 14020,\n",
       " 'age': 1361,\n",
       " 'older': 13313,\n",
       " 'under': 19406,\n",
       " 'redfield': 15531,\n",
       " 'signed': 16986,\n",
       " 'off': 13260,\n",
       " 'recommendation': 15491,\n",
       " 'panel': 13763,\n",
       " 'recommends': 15495,\n",
       " 'boxes': 3132,\n",
       " 'containing': 4542,\n",
       " 'prepared': 14701,\n",
       " 'sent': 16653,\n",
       " 'vaccinerollout38': 19934,\n",
       " 'airborne': 1428,\n",
       " 'heading': 8887,\n",
       " 'memphis': 11855,\n",
       " 'a306': 1011,\n",
       " 'n669fe': 12537,\n",
       " 'newly': 12808,\n",
       " 'approved': 1919,\n",
       " 'ccpvirus': 3713,\n",
       " '14': 160,\n",
       " 'firm': 7686,\n",
       " 'acuitas': 1183,\n",
       " 'heart': 8943,\n",
       " 'great': 8546,\n",
       " 'story': 17841,\n",
       " 'ubc': 19317,\n",
       " 'helped': 8987,\n",
       " 'wi': 20735,\n",
       " 'leaving': 10918,\n",
       " 'company': 4349,\n",
       " 'michigan': 11934,\n",
       " 'factory': 7368,\n",
       " 'eng': 6863,\n",
       " 'nhs': 12869,\n",
       " 'game': 8130,\n",
       " 'changer': 3830,\n",
       " 'hopenewsnhsheroes': 9205,\n",
       " 'bbcnews': 2533,\n",
       " 'covid19uk': 5007,\n",
       " 'inje': 9829,\n",
       " 'rival': 15991,\n",
       " 'companies': 4346,\n",
       " 'working': 20901,\n",
       " 'advisory': 1303,\n",
       " 'board': 3003,\n",
       " 'food': 7824,\n",
       " 'drug': 6458,\n",
       " 'administra': 1239,\n",
       " 'relieved': 15656,\n",
       " 'amazing': 1597,\n",
       " 'work': 20887,\n",
       " 'since': 17028,\n",
       " 'oxford_astrazeneca': 13617,\n",
       " 'bharatbiotech': 2742,\n",
       " 'most': 12353,\n",
       " 'submitted': 17945,\n",
       " 'applicat': 1871,\n",
       " 'trucks': 19157,\n",
       " 'filled': 7631,\n",
       " 'hit': 9111,\n",
       " 'road': 16012,\n",
       " 'mondayvia': 12283,\n",
       " 'live': 11153,\n",
       " 'coverage': 4929,\n",
       " 'loading': 11191,\n",
       " 'plant': 14368,\n",
       " 'global': 8345,\n",
       " '1611637': 222,\n",
       " 'offi': 13268,\n",
       " 'likely': 11082,\n",
       " 'worse': 20935,\n",
       " 'holidays': 9147,\n",
       " 'offering': 13265,\n",
       " 'bright': 3253,\n",
       " 'spot': 17518,\n",
       " 'fight': 7609,\n",
       " 'warned': 20471,\n",
       " 'allergic': 1512,\n",
       " 'ingredients': 9812,\n",
       " 'ok': 13301,\n",
       " 'late': 10831,\n",
       " 'discovering': 6062,\n",
       " 'both': 3105,\n",
       " 'pfizerbiontechand': 14070,\n",
       " 'led': 10923,\n",
       " 'packaged': 13690,\n",
       " 'advisors': 1302,\n",
       " 'tapped': 18320,\n",
       " 'review': 15894,\n",
       " 'payments': 13906,\n",
       " 'pray': 14642,\n",
       " 'th': 18509,\n",
       " 'dumasshe': 6490,\n",
       " 'did': 5957,\n",
       " 'anything': 1827,\n",
       " 'bet': 2701,\n",
       " 'kalingatv': 10475,\n",
       " 'basis': 2503,\n",
       " 'collaborate': 4237,\n",
       " 'usups': 19655,\n",
       " 'buy': 3433,\n",
       " 'pharmaceutical': 14193,\n",
       " 'alexion': 1479,\n",
       " '39': 635,\n",
       " 'billioncovid19vaccine': 2822,\n",
       " 'hatched': 8833,\n",
       " 'canada2': 3532,\n",
       " 'developed': 5904,\n",
       " 'scie': 16471,\n",
       " 'salute': 16285,\n",
       " 'healthcareheroes': 8909,\n",
       " 'risking': 15984,\n",
       " 'life': 11055,\n",
       " 'everyday': 7125,\n",
       " 'taking': 18290,\n",
       " 'patients': 13877,\n",
       " 'may': 11716,\n",
       " 'god': 8393,\n",
       " 'give': 8314,\n",
       " 'transparent': 19064,\n",
       " 'wrong': 20964,\n",
       " 'malaysia': 11482,\n",
       " 'pre': 14650,\n",
       " 'ordered': 13470,\n",
       " '2021': 357,\n",
       " 'plus': 14412,\n",
       " 'prepped': 14706,\n",
       " 'wall': 20433,\n",
       " 'street': 17861,\n",
       " 'journal': 10391,\n",
       " 'big': 2789,\n",
       " 'pharma': 14184,\n",
       " 'best': 2694,\n",
       " 'interests': 9981,\n",
       " 'those': 18696,\n",
       " 'hold': 9137,\n",
       " 'stock': 17794,\n",
       " 'itcoronavirus': 10137,\n",
       " 'entire': 6908,\n",
       " 'see': 16586,\n",
       " 'bigmac': 2797,\n",
       " 'splash': 17492,\n",
       " 'superpower': 18065,\n",
       " 'fi': 7598,\n",
       " 'stop': 17820,\n",
       " 'wearing': 20543,\n",
       " 'weeks': 20596,\n",
       " '2nd': 527,\n",
       " 'thencurious': 18613,\n",
       " 'test': 18482,\n",
       " 'vac': 19679,\n",
       " 'still': 17779,\n",
       " 'seems': 16595,\n",
       " 'unclear': 19396,\n",
       " 'if': 9435,\n",
       " 'reconstitute': 15500,\n",
       " 'site': 17113,\n",
       " 'home': 9155,\n",
       " 'operationwarpspeed': 13424,\n",
       " 'coronavaccine': 4644,\n",
       " 'cov': 4790,\n",
       " 'rolling': 16051,\n",
       " 'sundayvia': 18037,\n",
       " 'gives': 8319,\n",
       " 'allergy': 1518,\n",
       " 'pregnancy': 14684,\n",
       " 'concerns': 4414,\n",
       " 'vaccinevia': 20043,\n",
       " 'aviation': 2295,\n",
       " 'faa': 7342,\n",
       " 'saturday': 16367,\n",
       " 'facts': 7370,\n",
       " 'senator': 16634,\n",
       " 'nice': 12890,\n",
       " 'respect': 15819,\n",
       " 'faith': 7398,\n",
       " 'tell': 18436,\n",
       " 'truth': 19194,\n",
       " 'dev': 5895,\n",
       " 'soon': 17341,\n",
       " 'maskup': 11653,\n",
       " 'am': 1588,\n",
       " 'beyond': 2724,\n",
       " 'share': 16762,\n",
       " 'twitterpoll': 19290,\n",
       " 'dyk': 6533,\n",
       " 'bahrain': 2399,\n",
       " 'nations': 12648,\n",
       " 'discovered': 6061,\n",
       " 'europe': 7066,\n",
       " 'turkish': 19248,\n",
       " 'german': 8242,\n",
       " 'black': 2914,\n",
       " 'woman': 20840,\n",
       " 'giving': 8320,\n",
       " 'alright': 1563,\n",
       " 'indeed': 9658,\n",
       " 'relief': 15653,\n",
       " 'saudi': 16371,\n",
       " 'minister': 12015,\n",
       " 'showcased': 16922,\n",
       " 'sample': 16298,\n",
       " 'vacci': 19689,\n",
       " 'post': 14578,\n",
       " 'birth': 2885,\n",
       " 'rates': 15340,\n",
       " 'winter': 20784,\n",
       " 'supplier': 18076,\n",
       " 'fosun': 7903,\n",
       " 'payment': 13905,\n",
       " '125': 114,\n",
       " 'year': 21039,\n",
       " '50': 734,\n",
       " 'fmtnews': 7793,\n",
       " 'rolled': 16048,\n",
       " 'bringing': 3264,\n",
       " 'scepticism': 16448,\n",
       " '1000': 24,\n",
       " 'jackson': 10220,\n",
       " 'employees': 6805,\n",
       " 'successfully': 17971,\n",
       " 'oklahoma': 13306,\n",
       " 'historic': 9103,\n",
       " 'white': 20708,\n",
       " 'integri': 9952,\n",
       " 'rises': 15978,\n",
       " '16881': 231,\n",
       " 'sinovac': 17074,\n",
       " 'real': 15404,\n",
       " 'cool': 4607,\n",
       " 'boston': 3102,\n",
       " 'government': 8478,\n",
       " 'prepping': 14707,\n",
       " 'north': 13009,\n",
       " 'medical': 11781,\n",
       " 'center': 3755,\n",
       " 'talking': 18301,\n",
       " 'human': 9306,\n",
       " 'lives': 11162,\n",
       " 'herelet': 9017,\n",
       " 'repeat': 15711,\n",
       " 'mistake': 12073,\n",
       " 'past': 13852,\n",
       " 'dengvaxia': 5779,\n",
       " 'jeopardized': 10292,\n",
       " 'happened': 8757,\n",
       " 'got': 8455,\n",
       " 'holiday': 9146,\n",
       " 'present': 14713,\n",
       " 'ever': 7118,\n",
       " 'als': 1565,\n",
       " 'liberals': 11027,\n",
       " 'bureaucrats': 3386,\n",
       " 'bigpharma': 2799,\n",
       " 'pfizerbiontecht': 14121,\n",
       " 'pleased': 14398,\n",
       " 'important': 9576,\n",
       " 'possi': 14572,\n",
       " 'staff': 17643,\n",
       " 'applause': 1866,\n",
       " 'fridge': 7996,\n",
       " 'starting': 17688,\n",
       " 'program': 14897,\n",
       " 'distanced': 6120,\n",
       " 'patiently': 13876,\n",
       " 'waiting': 20410,\n",
       " 'video': 20251,\n",
       " 'atfirstvaccineshots': 2180,\n",
       " 'hey': 9044,\n",
       " 'say': 16397,\n",
       " 'someone': 17326,\n",
       " 'builds': 3358,\n",
       " 'antibodies': 1783,\n",
       " 'donate': 6257,\n",
       " 'despite': 5865,\n",
       " 'lebanon': 10920,\n",
       " 'dire': 6014,\n",
       " 'shortage': 16857,\n",
       " 'foreign': 7852,\n",
       " 'sign': 16982,\n",
       " '18': 249,\n",
       " 'deal': 5604,\n",
       " 'suppl': 18072,\n",
       " 'thead': 18576,\n",
       " 'epidemiologist': 6930,\n",
       " 'system': 18235,\n",
       " 'conference': 4444,\n",
       " 'receiving': 15459,\n",
       " 'nevada': 12780,\n",
       " 'hospital': 9224,\n",
       " 'ceo': 3769,\n",
       " 'van': 20119,\n",
       " 'houweling': 9265,\n",
       " 'umc': 19371,\n",
       " 'little': 11149,\n",
       " 'vial': 20237,\n",
       " 'carries': 3639,\n",
       " 'much': 12430,\n",
       " 'worked': 20888,\n",
       " 'tirelessly': 18823,\n",
       " 'westvirginiawvu': 20655,\n",
       " 'medicine': 11799,\n",
       " 'begun': 2605,\n",
       " 'mit': 12081,\n",
       " 'technology': 18404,\n",
       " 'incredibly': 9657,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_ # each vocab is stored in a dict that maps unique words to integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21365"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray() # each idx position corresponds to the integer values shown above \n",
    "# represents raw term frequencies, the # of times a term occurs in a document\n",
    "# 1 gram by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency inverse document frequency (td-idf) \n",
    "Assesses word relevancy. \n",
    "Downweight frequently occuring words in the feature vectors. \n",
    "The product of the term frequency and the inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['same folks said daikon paste could treat cytokine storm pfizerbiontech',\n",
       "       'coronavirus sputnikv astrazeneca pfizerbiontech moderna covid_19 russian vaccine is created to last 2 4 years',\n",
       "       'it is bit sad to claim the fame for success of vaccination on patriotic competition between usa canada uk and',\n",
       "       ...,\n",
       "       'pity as my personal preference would have been astrazeneca s vaccine but was offered pfizer instead wait un',\n",
       "       'who in close contact with russia on sputnikv certification',\n",
       "       'breakingus targets europe in smear campaign against russia s sputnikv vaccine kremlin source says'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tweets[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21355</th>\n",
       "      <th>21356</th>\n",
       "      <th>21357</th>\n",
       "      <th>21358</th>\n",
       "      <th>21359</th>\n",
       "      <th>21360</th>\n",
       "      <th>21361</th>\n",
       "      <th>21362</th>\n",
       "      <th>21363</th>\n",
       "      <th>21364</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 21365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   21355  21356  21357  21358  21359  21360  21361  21362  21363  21364  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[1 rows x 21365 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def identify_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "#lower idf value, less unique the word is to a particular text\n",
    "tfidf = TfidfVectorizer(preprocessor=\"\".join,\n",
    "                         use_idf=True, \n",
    "                         norm = \"l2\",\n",
    "                         smooth_idf=True)\n",
    "np.set_printoptions(precision=2)\n",
    "tfidf_vectors = tfidf.fit_transform(docs)\n",
    "\n",
    "tfidf_first = tfidf_vectors[0]\n",
    "# df = pd.DataFrame(tfidf_first.T.todense(),\n",
    "#                   index=tfidf_vectors.get_feature_names(), \n",
    "#                   columns= [\"tfidf\"])\n",
    "# df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "# takes raw term frequencies and transforms them into tf-idfs\n",
    "pd.DataFrame(tfidf_first.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "get_feature_names not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-443f3bedd97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: get_feature_names not found"
     ]
    }
   ],
   "source": [
    "tfidf_vectors.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## tokenizer splits the text corpora into individual elements\n",
    "## word stemming: transforming a word into its root form (maps related words  to the same stem)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "tweets[\"stemmed\"] = tweets[\"text\"].apply(lambda x: tokenizer_porter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/shiny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
    "        'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "        \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
    "        'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
    "        'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they',\n",
    "        'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "        'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those',\n",
    "        'a', 'an', 'the', 'and', 'if', 'or', 'because', 'as', \n",
    "        'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', \n",
    "        'between', 'into', 'through', 'during', 'before', \n",
    "        'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n",
    "        'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', \n",
    "        'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', \n",
    "        'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "        'such', 'only', 'own', 'same', 'so', 'than', \n",
    "        'too', 'very', 's', 't', 'just',  'now', 'd', 'll', 'm', 'o', 're', 've', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/shiny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop = stopwords.words(\"english\")\n",
    "    return [word for word in text if word not in stop]\n",
    "\n",
    "tweets[\"stop_removed\"] = tweets[\"stemmed\"].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [same, folk, said, daikon, past, could, treat,...\n",
       "2     [coronaviru, sputnikv, astrazeneca, pfizerbion...\n",
       "6     [it, is, bit, sad, to, claim, the, fame, for, ...\n",
       "9     [covidvaccinest, will, start, get, covid19vacc...\n",
       "10    [while, death, are, close, in, on, the, 300000...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"stemmed\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [folk, said, daikon, past, could, treat, cytok...\n",
       "2     [coronaviru, sputnikv, astrazeneca, pfizerbion...\n",
       "6     [bit, sad, claim, fame, success, vaccin, patri...\n",
       "9     [covidvaccinest, start, get, covid19vaccin, mo...\n",
       "10    [death, close, 300000, mark, million, peopl, w...\n",
       "Name: stop_removed, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"stop_removed\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/shiny/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "def lem(words):\n",
    "    lem_list = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in words:\n",
    "        lem_list.append(lemmatizer.lemmatize(word))\n",
    "    return lem_list\n",
    "\n",
    "tweets[\"lemmatized\"] = tweets[\"stop_removed\"].apply(lambda x: lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stop_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>same folks said daikon paste could treat cytok...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[same, folk, said, daikon, past, could, treat,...</td>\n",
       "      <td>[folk, said, daikon, past, could, treat, cytok...</td>\n",
       "      <td>[folk, said, daikon, past, could, treat, cytok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>coronavirus sputnikv astrazeneca pfizerbiontec...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[coronaviru, sputnikv, astrazeneca, pfizerbion...</td>\n",
       "      <td>[coronaviru, sputnikv, astrazeneca, pfizerbion...</td>\n",
       "      <td>[coronaviru, sputnikv, astrazeneca, pfizerbion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1337851215875608579</td>\n",
       "      <td>Gunther Fehlinger</td>\n",
       "      <td>Austria, Ukraine and Kosovo</td>\n",
       "      <td>End North Stream 2 now - the pipeline of corru...</td>\n",
       "      <td>2013-06-10 17:49:22</td>\n",
       "      <td>2731</td>\n",
       "      <td>5001</td>\n",
       "      <td>69344</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:06:00</td>\n",
       "      <td>it is bit sad to claim the fame for success of...</td>\n",
       "      <td>['vaccination']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>[it, is, bit, sad, to, claim, the, fame, for, ...</td>\n",
       "      <td>[bit, sad, claim, fame, success, vaccin, patri...</td>\n",
       "      <td>[bit, sad, claim, fame, success, vaccin, patri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1337842295857623042</td>\n",
       "      <td>Ch.Amjad Ali</td>\n",
       "      <td>Islamabad</td>\n",
       "      <td>#ProudPakistani #LovePakArmy #PMIK @insafiansp...</td>\n",
       "      <td>2012-11-12 04:18:12</td>\n",
       "      <td>671</td>\n",
       "      <td>2368</td>\n",
       "      <td>20469</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 19:30:33</td>\n",
       "      <td>covidvaccinestates will start getting covid19v...</td>\n",
       "      <td>['CovidVaccine', 'COVID19Vaccine', 'US', 'paku...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[covidvaccinest, will, start, get, covid19vacc...</td>\n",
       "      <td>[covidvaccinest, start, get, covid19vaccin, mo...</td>\n",
       "      <td>[covidvaccinest, start, get, covid19vaccin, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1337841934170255365</td>\n",
       "      <td>Tamer Yazar</td>\n",
       "      <td>Turkey-Israel</td>\n",
       "      <td>Im Market Analyst, also Editor... working (fre...</td>\n",
       "      <td>2009-09-17 16:45:16</td>\n",
       "      <td>1302</td>\n",
       "      <td>78</td>\n",
       "      <td>339</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 19:29:07</td>\n",
       "      <td>while deaths are closing in on the 300000 mark...</td>\n",
       "      <td>['PfizerBioNTech', 'Vaccine']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[while, death, are, close, in, on, the, 300000...</td>\n",
       "      <td>[death, close, 300000, mark, million, peopl, w...</td>\n",
       "      <td>[death, close, 300000, mark, million, peopl, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id          user_name                user_location  \\\n",
       "0   1340539111971516416         Rachel Roh    La Crescenta-Montrose, CA   \n",
       "2   1337858199140118533           eliüá±üáπüá™üá∫üëå                     Your Bed   \n",
       "6   1337851215875608579  Gunther Fehlinger  Austria, Ukraine and Kosovo   \n",
       "9   1337842295857623042       Ch.Amjad Ali                    Islamabad   \n",
       "10  1337841934170255365        Tamer Yazar                Turkey-Israel   \n",
       "\n",
       "                                     user_description         user_created  \\\n",
       "0   Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "2                                      heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "6   End North Stream 2 now - the pipeline of corru...  2013-06-10 17:49:22   \n",
       "9   #ProudPakistani #LovePakArmy #PMIK @insafiansp...  2012-11-12 04:18:12   \n",
       "10  Im Market Analyst, also Editor... working (fre...  2009-09-17 16:45:16   \n",
       "\n",
       "    user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0              405          1692             3247          False   \n",
       "2               10            88              155          False   \n",
       "6             2731          5001            69344          False   \n",
       "9              671          2368            20469          False   \n",
       "10            1302            78              339          False   \n",
       "\n",
       "                   date                                               text  \\\n",
       "0   2020-12-20 06:06:44  same folks said daikon paste could treat cytok...   \n",
       "2   2020-12-12 20:33:45  coronavirus sputnikv astrazeneca pfizerbiontec...   \n",
       "6   2020-12-12 20:06:00  it is bit sad to claim the fame for success of...   \n",
       "9   2020-12-12 19:30:33  covidvaccinestates will start getting covid19v...   \n",
       "10  2020-12-12 19:29:07  while deaths are closing in on the 300000 mark...   \n",
       "\n",
       "                                             hashtags               source  \\\n",
       "0                                  ['PfizerBioNTech']  Twitter for Android   \n",
       "2   ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "6                                     ['vaccination']      Twitter Web App   \n",
       "9   ['CovidVaccine', 'COVID19Vaccine', 'US', 'paku...      Twitter Web App   \n",
       "10                      ['PfizerBioNTech', 'Vaccine']      Twitter Web App   \n",
       "\n",
       "    retweets  favorites  is_retweet  \\\n",
       "0          0          0       False   \n",
       "2          0          0       False   \n",
       "6          0          4       False   \n",
       "9          0          0       False   \n",
       "10         0          0       False   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   [same, folk, said, daikon, past, could, treat,...   \n",
       "2   [coronaviru, sputnikv, astrazeneca, pfizerbion...   \n",
       "6   [it, is, bit, sad, to, claim, the, fame, for, ...   \n",
       "9   [covidvaccinest, will, start, get, covid19vacc...   \n",
       "10  [while, death, are, close, in, on, the, 300000...   \n",
       "\n",
       "                                         stop_removed  \\\n",
       "0   [folk, said, daikon, past, could, treat, cytok...   \n",
       "2   [coronaviru, sputnikv, astrazeneca, pfizerbion...   \n",
       "6   [bit, sad, claim, fame, success, vaccin, patri...   \n",
       "9   [covidvaccinest, start, get, covid19vaccin, mo...   \n",
       "10  [death, close, 300000, mark, million, peopl, w...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   [folk, said, daikon, past, could, treat, cytok...  \n",
       "2   [coronaviru, sputnikv, astrazeneca, pfizerbion...  \n",
       "6   [bit, sad, claim, fame, success, vaccin, patri...  \n",
       "9   [covidvaccinest, start, get, covid19vaccin, mo...  \n",
       "10  [death, close, 300000, mark, million, peopl, w...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The `text` argument passed to `__init__(text)` must be a string, not <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-119066efb52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_removed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# tweets['subjectivity'] = tweets['text'].apply(lambda x: subjectivity(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# tweets['sentiment'] = tweets['text'].apply(lambda x: senti(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-119066efb52d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_removed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# tweets['subjectivity'] = tweets['text'].apply(lambda x: subjectivity(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# tweets['sentiment'] = tweets['text'].apply(lambda x: senti(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-119066efb52d>\u001b[0m in \u001b[0;36mpolarity\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtestimonial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestimonial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 parser=None, classifier=None, clean_html=False):\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             raise TypeError('The `text` argument passed to `__init__(text)` '\n\u001b[0m\u001b[1;32m    385\u001b[0m                             'must be a string, not {0}'.format(type(text)))\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The `text` argument passed to `__init__(text)` must be a string, not <class 'list'>"
     ]
    }
   ],
   "source": [
    "def polarity(text):\n",
    "    testimonial = TextBlob(text)\n",
    "    polarity = testimonial.sentiment.polarity\n",
    "    return polarity\n",
    "\n",
    "\n",
    "def subjectivity(text):\n",
    "    testimonial = TextBlob(text)\n",
    "    subjectivity = testimonial.subjectivity\n",
    "    return subjectivity\n",
    "\n",
    "\n",
    "def senti(text, polarity_threshold=0):\n",
    "    testimonial = TextBlob(text)\n",
    "    senti = testimonial.sentiment.polarity\n",
    "    \n",
    "    if senti >= polarity_threshold:\n",
    "        return 1 # positive\n",
    "    elif np.abs(senti) == polarity_threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0 #negative\n",
    "    \n",
    "\n",
    "tweets['polarity'] = tweets['stop_removed'].apply(lambda x: polarity(x))\n",
    "# tweets['subjectivity'] = tweets['text'].apply(lambda x: subjectivity(x))\n",
    "# tweets['sentiment'] = tweets['text'].apply(lambda x: senti(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, tweets[\"sentiment\"], \n",
    "                                                    test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "param_grid = [{\"vect_ngram_range\": [(1,1)],\n",
    "              \"vect_stop_words\":[stop,None],\n",
    "              \"vect_tokenizer\":[tokenizer,\n",
    "                               tokenizer_porter],\n",
    "              \"clf_penalty\":[11,12],\n",
    "              \"clf_C\":[1.0, 10.0, 100.0]},\n",
    "              {\"vect_ngram_range\":[(1,1)],\n",
    "               \"vect_stop_words\": [stop, None],\n",
    "               \"vect_tokenizer\": [tokenizer,\n",
    "                                 tokenizer_porter],\n",
    "               \"vect_use_idf\": [False],\n",
    "               \"vect_norm\":[None],\n",
    "               \"clf_penalty\": [\"l1\", \"l2\"],\n",
    "               \"clf_C\": [1.0, 10.0, 100.0]}]\n",
    "lr_tfidf = Pipeline([(\"vect\", tfidf),\n",
    "                     (\"clf\", LogisticRegression(random_state = 0, solver= \"liblinear\"))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,scoring = \"accuracy\",\n",
    "                          cv = 5, verbose=2, n_jobs = -1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis - Christine's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(tweets[\"text\"], tweets[\"sentiment\"], \n",
    "#                                                     test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 3000, min_df= 10, stop_words = stopwords.words(\"english\"))\n",
    "processed_features = vectorizer.fit_transform(tweets[\"text\"]).toarray()\n",
    "processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)\n",
    "predictions = text_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: plot locations \n",
    "most_location = tweets[\"user_location\"].value_counts().head(15)\n",
    "fig, ax = plt.subplots()\n",
    "most_location.plot.bar()\n",
    "fig.suptitle(\"Number and Percentages of Tweets Based on Location\")\n",
    "ax.set_xlabel(\"Locations\")\n",
    "ax.set_ylabel(\"Number of tweets\")\n",
    "type(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean hashtags\n",
    "tweets[\"hashtags\"] = tweets[\"hashtags\"].apply(lambda x: re.sub(\"'\",\"\",x))\n",
    "tweets[\"hashtags\"] = tweets[\"hashtags\"].apply(lambda x: re.sub(\"\\[\",\"\",x))\n",
    "tweets[\"hashtags\"] = tweets[\"hashtags\"].apply(lambda x: re.sub(\"\\]\",\"\",x))\n",
    "tweets[\"hashtags\"] = tweets[\"hashtags\"].apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common hashtags \n",
    "hashtag_dict = {}\n",
    "for hashtag_list in tweets[\"hashtags\"]:\n",
    "    for hashtag in hashtag_list:\n",
    "        if hashtag.strip().lower() not in hashtag_dict:\n",
    "            hashtag_dict[hashtag.strip().lower()] = 0\n",
    "        hashtag_dict[hashtag.strip().lower()] += 1\n",
    "most_common_hashtag = sorted(hashtag_dict.items(), key = lambda x : x[1], reverse=True)\n",
    "most_common_hashtag[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of 2.37 hashtags\n",
    "tweets[\"hashtags_count\"] = tweets[\"hashtags\"].apply(lambda x: len(x))\n",
    "np.mean(tweets[\"hashtags_count\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_and_hashtags = tweets[[\"user_followers\",\"hashtags_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "followers_and_hashtags.plot(x=\"user_followers\", y = \"hashtags_count\",\n",
    "                            kind=\"scatter\", ax = ax)\n",
    "ax.set_xlabel(\"Number of User Followers (in 1e7)\")\n",
    "ax.set_ylabel(\"Number of Hashtags\")\n",
    "ax.set_title(\"Follower numbers vs Number of Hashtags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common words\n",
    "words_dict = {}\n",
    "for text in tweets[\"text\"].values:\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words(\"english\"):\n",
    "            continue\n",
    "        if word not in words_dict:\n",
    "            words_dict[word] = 0\n",
    "        words_dict[word] += 1 \n",
    "most_common = sorted(words_dict.items(), key = lambda x : x[1], reverse=True)\n",
    "most_common[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud text\n",
    "\n",
    "all_tweets = \"\".join(rev for rev in tweets[\"text\"])\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "wordcloud_img = WordCloud(max_font_size = 40, max_words = 50, background_color = \"white\").generate(all_tweets)\n",
    "ax.imshow(wordcloud_img)\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
